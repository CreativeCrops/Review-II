{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.5.5", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python"}, "kernelspec": {"display_name": "Python 3.5", "language": "python", "name": "python3"}}, "nbformat": 4, "cells": [{"outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 3, "data": {"text/plain": "                    State_Name District_Name  Crop_Year       Season  \\\n0  Andaman and Nicobar Islands      NICOBARS       2000  Kharif        \n1  Andaman and Nicobar Islands      NICOBARS       2000  Kharif        \n2  Andaman and Nicobar Islands      NICOBARS       2000  Kharif        \n3  Andaman and Nicobar Islands      NICOBARS       2000  Whole Year    \n4  Andaman and Nicobar Islands      NICOBARS       2000  Whole Year    \n\n                  Crop    Area  Production  \n0             Arecanut  1254.0      2000.0  \n1  Other Kharif pulses     2.0         1.0  \n2                 Rice   102.0       321.0  \n3               Banana   176.0       641.0  \n4            Cashewnut   720.0       165.0  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State_Name</th>\n      <th>District_Name</th>\n      <th>Crop_Year</th>\n      <th>Season</th>\n      <th>Crop</th>\n      <th>Area</th>\n      <th>Production</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Kharif</td>\n      <td>Arecanut</td>\n      <td>1254.0</td>\n      <td>2000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Kharif</td>\n      <td>Other Kharif pulses</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Kharif</td>\n      <td>Rice</td>\n      <td>102.0</td>\n      <td>321.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Whole Year</td>\n      <td>Banana</td>\n      <td>176.0</td>\n      <td>641.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Whole Year</td>\n      <td>Cashewnut</td>\n      <td>720.0</td>\n      <td>165.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}}], "metadata": {}, "cell_type": "code", "execution_count": 3, "source": "\nimport sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share your notebook.\nclient_37709ff639f94158ac87880ea34e5fa2 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='2EocrcsCeffWYQ6gvqKBbWJ9zPaoLaxYaUZp9F8hsBBr',\n    ibm_auth_endpoint=\"https://iam.eu-gb.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.eu-geo.objectstorage.service.networklayer.com')\n\nbody = client_37709ff639f94158ac87880ea34e5fa2.get_object(Bucket='dataanalysis-donotdelete-pr-y18rl850r7xhqv',Key='apy.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": 4, "source": "\nimport numpy as np\nimport pandas\n\n#Class for Popularity based Recommender System model\nclass popularity_recommender_py():\n    def __init__(self):\n        self.train_data = None\n        self.user_id = None\n        self.item_id = None\n        self.popularity_recommendations = None\n        \n    #Create the popularity based recommender system model\n    def create(self, train_data, user_id, item_id):\n        self.train_data = train_data\n        self.user_id = user_id\n        self.item_id = item_id\n\n        #Get a count of user_ids for each unique crop as recommendation score\n        train_data_grouped = train_data.groupby([self.item_id]).agg({self.user_id: 'count'}).reset_index()\n        train_data_grouped.rename(columns = {'user_id': 'score'},inplace=True)\n    \n        #Sort the crops based upon recommendation score\n        train_data_sort = train_data_grouped.sort_values(['score', self.item_id], ascending = [0,1])\n    \n        #Generate a recommendation rank based upon score\n        train_data_sort['Rank'] = train_data_sort['score'].rank(ascending=0, method='first')\n        \n        #Get the top 10 recommendations\n        self.popularity_recommendations = train_data_sort.head(10)\n\n    #Use the popularity based recommender system model to\n    #make recommendations\n    def recommend(self, user_id):    \n        user_recommendations = self.popularity_recommendations\n        \n        #Add user_id column for which the recommendations are being generated\n        user_recommendations['user_id'] = user_id\n    \n        #Bring user_id column to the front\n        cols = user_recommendations.columns.tolist()\n        cols = cols[-1:] + cols[:-1]\n        user_recommendations = user_recommendations[cols]\n        \n        return user_recommendations\n    \n"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": 5, "source": "\n#Class for Item similarity based Recommender System model\nclass item_similarity_recommender_py():\n    def __init__(self):\n        self.train_data = None\n        self.user_id = None\n        self.item_id = None\n        self.cooccurence_matrix = None\n        self.crops_dict = None\n        self.rev_crops_dict = None\n        self.item_similarity_recommendations = None\n        \n    #Get unique items (crops) corresponding to a given user\n    def get_user_items(self, user):\n        user_data = self.train_data[self.train_data[self.user_id] == user]\n        user_items = list(user_data[self.item_id].unique())\n        \n        return user_items\n        \n    #Get unique users for a given item (crop)\n    def get_item_users(self, item):\n        item_data = self.train_data[self.train_data[self.item_id] == item]\n        item_users = set(item_data[self.user_id].unique())\n            \n        return item_users\n        \n    #Get unique items (crops) in the training data\n    def get_all_items_train_data(self):\n        all_items = list(self.train_data[self.item_id].unique())\n            \n        return all_items\n        \n    #Construct cooccurence matrix\n    def construct_cooccurence_matrix(self, user_crops, all_crops):\n            \n        #Get users for all crops in user_crops.\n        user_crops_users = []        \n        for i in range(0, len(user_crops)):\n            user_crops_users.append(self.get_item_users(user_crops[i]))\n            \n        #Initialize the item cooccurence matrix of size \n        #len(user_crops) X len(crops)\n        cooccurence_matrix = np.matrix(np.zeros(shape=(len(user_crops), len(all_crops))), float)\n           \n        #Calculate similarity between user crops and all unique crops\n        #in the training data\n        for i in range(0,len(all_crops)):\n            #Calculate unique listeners (users) of crop (item) i\n            crops_i_data = self.train_data[self.train_data[self.item_id] == all_crops[i]]\n            users_i = set(crops_i_data[self.user_id].unique())\n            \n            for j in range(0,len(user_crops)):       \n                    \n                #Get unique listeners (users) of crop (item) j\n                users_j = user_crops_users[j]\n                    \n                #Calculate intersection of listeners of crops i and j\n                users_intersection = users_i.intersection(users_j)\n                \n                #Calculate cooccurence_matrix[i,j] as Jaccard Index\n                if len(users_intersection) != 0:\n                    #Calculate union of listeners of crops i and j\n                    users_union = users_i.union(users_j)\n                    \n                    cooccurence_matrix[j,i] = float(len(users_intersection))/float(len(users_union))\n                else:\n                    cooccurence_matrix[j,i] = 0\n                    \n        \n        return cooccurence_matrix\n\n    \n    #Use the cooccurence matrix to make top recommendations\n    def generate_top_recommendations(self, user, cooccurence_matrix, all_crops, user_crops):\n        print(\"Non zero values in cooccurence_matrix :%d\" % np.count_nonzero(cooccurence_matrix))\n        \n        #Calculate a weighted average of the scores in cooccurence matrix for all user crops.\n        user_sim_scores = cooccurence_matrix.sum(axis=0)/float(cooccurence_matrix.shape[0])\n        user_sim_scores = np.array(user_sim_scores)[0].tolist()\n \n        #Sort the indices of user_sim_scores based upon their value\n        #Also maintain the corresponding score\n        sort_index = sorted(((e,i) for i,e in enumerate(list(user_sim_scores))), reverse=True)\n    \n        #Create a dataframe from the following\n        columns = ['user_id', 'crop', 'score', 'rank']\n        #index = np.arange(1) # array of numbers for the number of samples\n        df = pandas.DataFrame(columns=columns)\n         \n        #Fill the dataframe with top 10 item based recommendations\n        rank = 1 \n        for i in range(0,len(sort_index)):\n            if ~np.isnan(sort_index[i][0]) and all_crops[sort_index[i][1]] not in user_crops and rank <= 10:\n                df.loc[len(df)]=[user,all_crops[sort_index[i][1]],sort_index[i][0],rank]\n                rank = rank+1\n        \n        #Handle the case where there are no recommendations\n        if df.shape[0] == 0:\n            print(\"The current user has no crops for training the item similarity based recommendation model.\")\n            return -1\n        else:\n            return df\n \n    #Create the item similarity based recommender system model\n    def create(self, train_data, user_id, item_id):\n        self.train_data = train_data\n        self.user_id = user_id\n        self.item_id = item_id\n\n    #Use the item similarity based recommender system model to\n    #make recommendations\n    def recommend(self, user):\n        \n        #A. Get all unique crops for this user\n        user_crops = self.get_user_items(user)    \n            \n        print(\"No. of unique crops for the user: %d\" % len(user_crops))\n        \n        #B. Get all unique items (crops) in the training data\n        all_crops = self.get_all_items_train_data()\n        \n        print(\"no. of unique crops in the training set: %d\" % len(all_crops))\n         \n        #C. Construct item cooccurence matrix of size \n        #len(user_crops) X len(crops)\n        cooccurence_matrix = self.construct_cooccurence_matrix(user_crops, all_crops)\n        \n        #D. Use the cooccurence matrix to make recommendations\n        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_crops, user_crops)\n                \n        return df_recommendations\n    \n    #Get similar items to given items\n    def get_similar_items(self, item_list):\n        \n        user_crops = item_list\n        \n        #B. Get all unique items (crops) in the training data\n        all_crops = self.get_all_items_train_data()\n        \n        print(\"no. of unique crops in the training set: %d\" % len(all_crops))\n         \n        #C. Construct item cooccurence matrix of size \n        #len(user_crops) X len(crops)\n        cooccurence_matrix = self.construct_cooccurence_matrix(user_crops, all_crops)\n        \n        #D. Use the cooccurence matrix to make recommendations\n        user = \"\"\n        df_recommendations = self.generate_top_recommendations(user, cooccurence_matrix, all_crops, user_crops)\n         \n        return df_recommendations\n\n"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": 6, "source": "\nimport random\n\nclass precision_recall_calculator():\n    \n    def __init__(self, test_data, train_data, pm, is_model):\n        self.test_data = test_data\n        self.train_data = train_data\n        self.user_test_sample = None\n        self.model1 = pm\n        self.model2 = is_model\n        \n        self.ism_training_dict = dict()\n        self.pm_training_dict = dict()\n        self.test_dict = dict()\n    \n    #Method to return random percentage of values from a list\n    def remove_percentage(self, list_a, percentage):\n        k = int(len(list_a) * percentage)\n        random.seed(0)\n        indicies = random.sample(range(len(list_a)), k)\n        new_list = [list_a[i] for i in indicies]\n    \n        return new_list\n    \n    #Create a test sample of users for use in calculating precision\n    #and recall\n    def create_user_test_sample(self, percentage):\n        #Find users common between training and test set\n        users_test_and_training = list(set(self.test_data['user_id'].unique()).intersection(set(self.train_data['user_id'].unique())))\n        print(\"Length of user_test_and_training:%d\" % len(users_test_and_training))\n\n        #Take only random user_sample of users for evaluations\n        self.users_test_sample = self.remove_percentage(users_test_and_training, percentage)\n\n        print(\"Length of user sample:%d\" % len(self.users_test_sample))\n        \n    #Method to generate recommendations for users in the user test sample\n    def get_test_sample_recommendations(self):\n        #For these test_sample users, get top 10 recommendations from training set\n        #self.ism_training_dict = {}\n        #self.pm_training_dict = {}\n\n        #self.test_dict = {}\n\n        for user_id in self.users_test_sample:\n            #Get items for user_id from item similarity model\n            print(\"Getting recommendations for user:%s\" % user_id)\n            user_sim_items = self.model2.recommend(user_id)\n            self.ism_training_dict[user_id] = list(user_sim_items[\"crop\"])\n    \n            #Get items for user_id from popularity model\n            user_sim_items = self.model1.recommend(user_id)\n            self.pm_training_dict[user_id] = list(user_sim_items[\"crop\"])\n    \n            #Get items for user_id from test_data\n            test_data_user = self.test_data[self.test_data['user_id'] == user_id]\n            self.test_dict[user_id] = set(test_data_user['crop'].unique() )\n    \n    #Method to calculate the precision and recall measures\n    def calculate_precision_recall(self):\n        #Create cutoff list for precision and recall calculation\n        cutoff_list = list(range(1,11))\n\n\n        #For each distinct cutoff:\n        #    1. For each distinct user, calculate precision and recall.\n        #    2. Calculate average precision and recall.\n\n        ism_avg_precision_list = []\n        ism_avg_recall_list = []\n        pm_avg_precision_list = []\n        pm_avg_recall_list = []\n\n\n        num_users_sample = len(self.users_test_sample)\n        for N in cutoff_list:\n            ism_sum_precision = 0\n            ism_sum_recall = 0\n            pm_sum_precision = 0\n            pm_sum_recall = 0\n            ism_avg_precision = 0\n            ism_avg_recall = 0\n            pm_avg_precision = 0\n            pm_avg_recall = 0\n\n            for user_id in self.users_test_sample:\n                ism_hitset = self.test_dict[user_id].intersection(set(self.ism_training_dict[user_id][0:N]))\n                pm_hitset = self.test_dict[user_id].intersection(set(self.pm_training_dict[user_id][0:N]))\n                testset = self.test_dict[user_id]\n        \n                pm_sum_precision += float(len(pm_hitset))/float(N)\n                pm_sum_recall += float(len(pm_hitset))/float(len(testset))\n\n                ism_sum_precision += float(len(ism_hitset))/float(len(testset))\n                ism_sum_recall += float(len(ism_hitset))/float(N)\n        \n            pm_avg_precision = pm_sum_precision/float(num_users_sample)\n            pm_avg_recall = pm_sum_recall/float(num_users_sample)\n    \n            ism_avg_precision = ism_sum_precision/float(num_users_sample)\n            ism_avg_recall = ism_sum_recall/float(num_users_sample)\n\n            ism_avg_precision_list.append(ism_avg_precision)\n            ism_avg_recall_list.append(ism_avg_recall)\n    \n            pm_avg_precision_list.append(pm_avg_precision)\n            pm_avg_recall_list.append(pm_avg_recall)\n            \n        return (pm_avg_precision_list, pm_avg_recall_list, ism_avg_precision_list, ism_avg_recall_list)\n     \n\n    #A wrapper method to calculate all the evaluation measures\n    def calculate_measures(self, percentage):\n        #Create a test sample of users\n        self.create_user_test_sample(percentage)\n        \n        #Generate recommendations for the test sample users\n        self.get_test_sample_recommendations()\n        \n        #Calculate precision and recall at different cutoff values\n        #for popularity mode (pm) as well as item similarity model (ism)\n        \n        return self.calculate_precision_recall()\n        #return (pm_avg_precision_list, pm_avg_recall_list, ism_avg_precision_list, ism_avg_recall_list)    \n\n"}, {"outputs": [{"output_type": "stream", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n", "name": "stderr"}], "metadata": {}, "cell_type": "code", "execution_count": 7, "source": "import pandas\nfrom sklearn.cross_validation import train_test_split\nimport numpy as np\nimport time\nfrom sklearn.externals import joblib"}, {"outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 8, "data": {"text/plain": "                    State_Name District_Name  Crop_Year       Season  \\\n0  Andaman and Nicobar Islands      NICOBARS       2000  Kharif        \n1  Andaman and Nicobar Islands      NICOBARS       2000  Kharif        \n2  Andaman and Nicobar Islands      NICOBARS       2000  Kharif        \n3  Andaman and Nicobar Islands      NICOBARS       2000  Whole Year    \n4  Andaman and Nicobar Islands      NICOBARS       2000  Whole Year    \n\n                  Crop    Area  Production  \n0             Arecanut  1254.0      2000.0  \n1  Other Kharif pulses     2.0         1.0  \n2                 Rice   102.0       321.0  \n3               Banana   176.0       641.0  \n4            Cashewnut   720.0       165.0  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State_Name</th>\n      <th>District_Name</th>\n      <th>Crop_Year</th>\n      <th>Season</th>\n      <th>Crop</th>\n      <th>Area</th>\n      <th>Production</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Kharif</td>\n      <td>Arecanut</td>\n      <td>1254.0</td>\n      <td>2000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Kharif</td>\n      <td>Other Kharif pulses</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Kharif</td>\n      <td>Rice</td>\n      <td>102.0</td>\n      <td>321.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Whole Year</td>\n      <td>Banana</td>\n      <td>176.0</td>\n      <td>641.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Andaman and Nicobar Islands</td>\n      <td>NICOBARS</td>\n      <td>2000</td>\n      <td>Whole Year</td>\n      <td>Cashewnut</td>\n      <td>720.0</td>\n      <td>165.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}}], "metadata": {}, "cell_type": "code", "execution_count": 8, "source": "crop_df =  df_data_1\ncrop_df.head()"}, {"outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 9, "data": {"text/plain": "246091"}}], "metadata": {}, "cell_type": "code", "execution_count": 9, "source": "len(crop_df)"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": 10, "source": "crop_df = crop_df"}, {"outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 11, "data": {"text/plain": "                      Crop   Area  percentage\n95                    Rice  15104    6.137567\n59                   Maize  13947    5.667416\n63       Moong(Green Gram)  10318    4.192758\n116                   Urad   9850    4.002584\n102                Sesamum   9046    3.675876\n43               Groundnut   8834    3.589729\n106              Sugarcane   7921    3.218728\n119                  Wheat   7899    3.209788\n92       Rapeseed &Mustard   7592    3.085038\n3                Arhar/Tur   7578    3.079349\n41                    Gram   7361    2.991170\n48                   Jowar   7065    2.870889\n67                   Onion   7012    2.849352\n87                  Potato   6931    2.816438\n37            Dry chillies   6489    2.636829\n107              Sunflower   5571    2.263797\n6                    Bajra   5427    2.205282\n103          Small millets   4652    1.890358\n81   Peas & beans (Pulses)   4524    1.838344\n33            Cotton(lint)   4518    1.835906\n57                 Linseed   4405    1.789988\n61                  Masoor   4224    1.716438\n114               Turmeric   4202    1.707498\n8                   Barley   4199    1.706279\n108           Sweet potato   4198    1.705873\n90                    Ragi   4145    1.684336\n45              Horse-gram   3902    1.585592\n74     Other Kharif pulses   3659    1.486848\n25             Castor seed   3376    1.371850\n32               Coriander   3369    1.369006\n..                     ...    ...         ...\n94             Ribed Guard     38    0.015441\n120                    Yam     36    0.014629\n24           Cashewnut Raw     35    0.014222\n56                  Lentil     31    0.012597\n97                  Rubber     29    0.011784\n21                  Carrot     28    0.011378\n23     Cashewnut Processed     21    0.008533\n1      Arcanut (Processed)     20    0.008127\n5            Atcanut (Raw)     20    0.008127\n9                     Bean     20    0.008127\n50            Jute & mesta     20    0.008127\n31         Cond-spcs other     18    0.007314\n91          Rajmash Kholar     18    0.007314\n11               Beet Root     16    0.006502\n51                   Kapas     12    0.004876\n12                     Ber     11    0.004470\n30               Colocosia     11    0.004470\n80       Peas  (vegetable)     11    0.004470\n96      Ricebean (nagadal)     10    0.004064\n121           other fibres     10    0.004064\n47                 Jobster      9    0.003657\n82                 Perilla      9    0.003657\n115                 Turnip      8    0.003251\n29                  Coffee      6    0.002438\n58                  Litchi      6    0.002438\n79                    Pear      6    0.002438\n84                   Plums      6    0.002438\n0                    Apple      4    0.001625\n78                   Peach      4    0.001625\n72         Other Dry Fruit      1    0.000406\n\n[124 rows x 3 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Crop</th>\n      <th>Area</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>95</th>\n      <td>Rice</td>\n      <td>15104</td>\n      <td>6.137567</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Maize</td>\n      <td>13947</td>\n      <td>5.667416</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>Moong(Green Gram)</td>\n      <td>10318</td>\n      <td>4.192758</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>Urad</td>\n      <td>9850</td>\n      <td>4.002584</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>Sesamum</td>\n      <td>9046</td>\n      <td>3.675876</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Groundnut</td>\n      <td>8834</td>\n      <td>3.589729</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>Sugarcane</td>\n      <td>7921</td>\n      <td>3.218728</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>Wheat</td>\n      <td>7899</td>\n      <td>3.209788</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>Rapeseed &amp;Mustard</td>\n      <td>7592</td>\n      <td>3.085038</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arhar/Tur</td>\n      <td>7578</td>\n      <td>3.079349</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Gram</td>\n      <td>7361</td>\n      <td>2.991170</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>Jowar</td>\n      <td>7065</td>\n      <td>2.870889</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Onion</td>\n      <td>7012</td>\n      <td>2.849352</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Potato</td>\n      <td>6931</td>\n      <td>2.816438</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Dry chillies</td>\n      <td>6489</td>\n      <td>2.636829</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>Sunflower</td>\n      <td>5571</td>\n      <td>2.263797</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Bajra</td>\n      <td>5427</td>\n      <td>2.205282</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>Small millets</td>\n      <td>4652</td>\n      <td>1.890358</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>Peas &amp; beans (Pulses)</td>\n      <td>4524</td>\n      <td>1.838344</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Cotton(lint)</td>\n      <td>4518</td>\n      <td>1.835906</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Linseed</td>\n      <td>4405</td>\n      <td>1.789988</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Masoor</td>\n      <td>4224</td>\n      <td>1.716438</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>Turmeric</td>\n      <td>4202</td>\n      <td>1.707498</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Barley</td>\n      <td>4199</td>\n      <td>1.706279</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>Sweet potato</td>\n      <td>4198</td>\n      <td>1.705873</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>Ragi</td>\n      <td>4145</td>\n      <td>1.684336</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>Horse-gram</td>\n      <td>3902</td>\n      <td>1.585592</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Other Kharif pulses</td>\n      <td>3659</td>\n      <td>1.486848</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Castor seed</td>\n      <td>3376</td>\n      <td>1.371850</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Coriander</td>\n      <td>3369</td>\n      <td>1.369006</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>Ribed Guard</td>\n      <td>38</td>\n      <td>0.015441</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>Yam</td>\n      <td>36</td>\n      <td>0.014629</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Cashewnut Raw</td>\n      <td>35</td>\n      <td>0.014222</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>Lentil</td>\n      <td>31</td>\n      <td>0.012597</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Rubber</td>\n      <td>29</td>\n      <td>0.011784</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Carrot</td>\n      <td>28</td>\n      <td>0.011378</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Cashewnut Processed</td>\n      <td>21</td>\n      <td>0.008533</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Arcanut (Processed)</td>\n      <td>20</td>\n      <td>0.008127</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Atcanut (Raw)</td>\n      <td>20</td>\n      <td>0.008127</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Bean</td>\n      <td>20</td>\n      <td>0.008127</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>Jute &amp; mesta</td>\n      <td>20</td>\n      <td>0.008127</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Cond-spcs other</td>\n      <td>18</td>\n      <td>0.007314</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>Rajmash Kholar</td>\n      <td>18</td>\n      <td>0.007314</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Beet Root</td>\n      <td>16</td>\n      <td>0.006502</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Kapas</td>\n      <td>12</td>\n      <td>0.004876</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Ber</td>\n      <td>11</td>\n      <td>0.004470</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Colocosia</td>\n      <td>11</td>\n      <td>0.004470</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>Peas  (vegetable)</td>\n      <td>11</td>\n      <td>0.004470</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Ricebean (nagadal)</td>\n      <td>10</td>\n      <td>0.004064</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>other fibres</td>\n      <td>10</td>\n      <td>0.004064</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>Jobster</td>\n      <td>9</td>\n      <td>0.003657</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>Perilla</td>\n      <td>9</td>\n      <td>0.003657</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>Turnip</td>\n      <td>8</td>\n      <td>0.003251</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Coffee</td>\n      <td>6</td>\n      <td>0.002438</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Litchi</td>\n      <td>6</td>\n      <td>0.002438</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>Pear</td>\n      <td>6</td>\n      <td>0.002438</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>Plums</td>\n      <td>6</td>\n      <td>0.002438</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Apple</td>\n      <td>4</td>\n      <td>0.001625</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Peach</td>\n      <td>4</td>\n      <td>0.001625</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>Other Dry Fruit</td>\n      <td>1</td>\n      <td>0.000406</td>\n    </tr>\n  </tbody>\n</table>\n<p>124 rows \u00d7 3 columns</p>\n</div>"}}], "metadata": {}, "cell_type": "code", "execution_count": 11, "source": "crop_grouped = crop_df.groupby(['Crop']).agg({'Area': 'count'}).reset_index()\ngrouped_sum = crop_grouped['Area'].sum()\ncrop_grouped['percentage']  = crop_grouped['Area'].div(grouped_sum)*100\ncrop_grouped.sort_values(['Area', 'Crop'], ascending = [0,1])"}, {"outputs": [], "metadata": {}, "cell_type": "code", "execution_count": 12, "source": "crops = crop_df['Crop'].unique()"}, {"outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 13, "data": {"text/plain": "124"}}], "metadata": {}, "cell_type": "code", "execution_count": 13, "source": "len(crops)"}, {"outputs": [{"output_type": "execute_result", "metadata": {}, "execution_count": 14, "data": {"text/plain": "array(['Arecanut', 'Other Kharif pulses', 'Rice', 'Banana', 'Cashewnut',\n       'Coconut ', 'Dry ginger', 'Sugarcane', 'Sweet potato', 'Tapioca',\n       'Black pepper', 'Dry chillies', 'other oilseeds', 'Turmeric',\n       'Maize', 'Moong(Green Gram)', 'Urad', 'Arhar/Tur', 'Groundnut',\n       'Sunflower', 'Bajra', 'Castor seed', 'Cotton(lint)', 'Horse-gram',\n       'Jowar', 'Korra', 'Ragi', 'Tobacco', 'Gram', 'Wheat', 'Masoor',\n       'Sesamum', 'Linseed', 'Safflower', 'Onion', 'other misc. pulses',\n       'Samai', 'Small millets', 'Coriander', 'Potato',\n       'Other  Rabi pulses', 'Soyabean', 'Beans & Mutter(Vegetable)',\n       'Bhindi', 'Brinjal', 'Citrus Fruit', 'Cucumber', 'Grapes', 'Mango',\n       'Orange', 'other fibres', 'Other Fresh Fruits', 'Other Vegetables',\n       'Papaya', 'Pome Fruit', 'Tomato', 'Rapeseed &Mustard', 'Mesta',\n       'Cowpea(Lobia)', 'Lemon', 'Pome Granet', 'Sapota', 'Cabbage',\n       'Peas  (vegetable)', 'Niger seed', 'Bottle Gourd', 'Sannhamp',\n       'Varagu', 'Garlic', 'Ginger', 'Oilseeds total', 'Pulses total',\n       'Jute', 'Peas & beans (Pulses)', 'Blackgram', 'Paddy', 'Pineapple',\n       'Barley', 'Khesari', 'Guar seed', 'Moth', 'Other Cereals & Millets',\n       'Cond-spcs other', 'Turnip', 'Carrot', 'Redish',\n       'Arcanut (Processed)', 'Atcanut (Raw)', 'Cashewnut Processed',\n       'Cashewnut Raw', 'Cardamom', 'Rubber', 'Bitter Gourd', 'Drum Stick',\n       'Jack Fruit', 'Snak Guard', 'Pump Kin', 'Tea', 'Coffee',\n       'Cauliflower', 'Other Citrus Fruit', 'Water Melon',\n       'Total foodgrain', 'Kapas', 'Colocosia', 'Lentil', 'Bean',\n       'Jobster', 'Perilla', 'Rajmash Kholar', 'Ricebean (nagadal)',\n       'Ash Gourd', 'Beet Root', 'Lab-Lab', 'Ribed Guard', 'Yam', 'Apple',\n       'Peach', 'Pear', 'Plums', 'Litchi', 'Ber', 'Other Dry Fruit',\n       'Jute & mesta'], dtype=object)"}}], "metadata": {}, "cell_type": "code", "execution_count": 14, "source": "crops"}], "nbformat_minor": 1}